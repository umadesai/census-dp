{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future document for tutorial on the concept of budget in differencial privacy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subjects to cover: \n",
    "1. Sequential Composition as demonstrated by asking for mean then median of the same data constrasted with doing DP over the initial data to comparte budget usage. \n",
    "2. Parallel composition as demonstrated by doing the same analysis over different geographic location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Composition Theorem\n",
    "It is critical to recognize that privacy losses *accumulate*. When two answers are returned to an adversary, the total privacy loss is twice as large, and the privacy guarantee is half as strong. This cumulative property is a consequence of the **composition theorem**. In essence, with each new query, additional information about the sensitive data is released. \n",
    "\n",
    "### Maximum Privacy Loss\n",
    "How does differential privacy work if the privacy loss grows so quickly? To ensure a meaningful privacy guarantee, data curators can enforce a **maximum privacy loss**. If the number of queries exceeds the threshold, then the privacy guarantee becomes too weak and the curator stops answering queries. The maximum privacy loss is called the privacy budget. We can think of each query as a privacy ‘expense’ which incurs an incremental privacy loss. Setting the privacy budget is ultimately a policy question.\n",
    "\n",
    "One of the most powerful features of differential privacy is its robustness under composition. While it cannot get around the fundamental law that privacy risk increases when multiple analyses are performed on the same individual’s data, differential privacy guarantees that privacy risk accumulates in a bounded way. Despite the\n",
    "accumulation of risk, two differentially private analyses cannot be\n",
    "combined in a way that leads to a privacy breach that is disproportionate to the privacy risk associated with each analysis in isolation. \n",
    "\n",
    "### Utilizing Your Privacy Budget\n",
    "The privacy loss parameter ε can be thought of as a “privacy\n",
    "budget” to be spent by different analyses of individuals’ data. If a single analysis is expected to be performed on a given set of data, then one might allow this analysis to exhaust the entire privacy budget ε. However, a more typical scenario is that several analyses are expected to be run on a dataset, and, therefore, one needs to calculate the total utilization of the privacy budget by these analyses. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
