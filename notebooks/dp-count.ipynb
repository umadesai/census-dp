{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Count queries\n",
    "The most basic statistical tool, a count query, returns an estimate of the number of individual records in the data satisfying a specific condition. Differentially private answers to count queries\n",
    "can be obtained through the addition of random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, zipfile, io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores one disclosure avoidance technique that injects Laplace-distributed noise to tabulated Public Use Microdata Sample(PUMS) data. First, let's download the PUMS data and read it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://www2.census.gov/programs-surveys/acs/data/pums/2017/5-Year/csv_ppa.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extract('psam_p42.csv')\n",
    "pa = pd.read_csv(\"psam_p42.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's filter the data to contain only relevant variables and people. In this example we will focus on educational attainment and race for people above the age of 18. For variable defintions, see: https://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMS_Data_Dictionary_2017.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUMA</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>RAC2P</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>WAGP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>AGEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3401</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75200.0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3401</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36400.0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUMA  RAC1P  RAC2P  SCHL  WAGP    PINCP  AGEP\n",
       "0  1300      1      1  16.0   0.0   7300.0    83\n",
       "1  1300      1      1  21.0   0.0  11000.0    69\n",
       "2  3401      1      1  22.0   0.0  75200.0    68\n",
       "3  3401      1      1  21.0   0.0  36400.0    67\n",
       "4  4002      1      1  19.0   0.0   2600.0    47"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering geographic location, race, educational attainment, total income in past 12 months and age for all 18+ PA persons\n",
    "new_pa = pa.query(\"AGEP>=18\").filter(items=['PUMA','RAC1P','RAC2P','SCHL','WAGP','PINCP','AGEP'])\n",
    "new_pa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No schooling</th>\n",
       "      <th>preschool</th>\n",
       "      <th>K</th>\n",
       "      <th>Grade 1</th>\n",
       "      <th>Grade 2</th>\n",
       "      <th>Grade 3</th>\n",
       "      <th>Grade 4</th>\n",
       "      <th>Grade 5</th>\n",
       "      <th>Grade 6</th>\n",
       "      <th>Grade 7</th>\n",
       "      <th>...</th>\n",
       "      <th>HS diploma</th>\n",
       "      <th>GED</th>\n",
       "      <th>some college</th>\n",
       "      <th>1+ year college</th>\n",
       "      <th>Associate</th>\n",
       "      <th>Bachelor</th>\n",
       "      <th>Master</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Doctorate</th>\n",
       "      <th>ALL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAC1P</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3749.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>...</td>\n",
       "      <td>155828.0</td>\n",
       "      <td>17058.0</td>\n",
       "      <td>28869.0</td>\n",
       "      <td>52859.0</td>\n",
       "      <td>37029.0</td>\n",
       "      <td>76093.0</td>\n",
       "      <td>33779.0</td>\n",
       "      <td>7413.0</td>\n",
       "      <td>5328.0</td>\n",
       "      <td>456843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>633.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10704.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>2696.0</td>\n",
       "      <td>6011.0</td>\n",
       "      <td>2318.0</td>\n",
       "      <td>3326.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>35469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>571.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>2982.0</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>12446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>225.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>877.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>6079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5280.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>171441.0</td>\n",
       "      <td>20472.0</td>\n",
       "      <td>33079.0</td>\n",
       "      <td>62082.0</td>\n",
       "      <td>40643.0</td>\n",
       "      <td>83742.0</td>\n",
       "      <td>37738.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>6359.0</td>\n",
       "      <td>516824.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       No schooling  preschool     K  Grade 1  Grade 2  Grade 3  Grade 4  \\\n",
       "RAC1P                                                                      \n",
       "1            3749.0       54.0  48.0     53.0     73.0    230.0    192.0   \n",
       "2             633.0       10.0  12.0      9.0     20.0     39.0     27.0   \n",
       "3              10.0        1.0   1.0      NaN      1.0      2.0      NaN   \n",
       "4               NaN        NaN   NaN      NaN      NaN      NaN      NaN   \n",
       "5              10.0        NaN   NaN      2.0      4.0      2.0      4.0   \n",
       "6             571.0        1.0   4.0      9.0     21.0     32.0     35.0   \n",
       "7               5.0        NaN   NaN      NaN      NaN      NaN      NaN   \n",
       "8             225.0        2.0   2.0     12.0     14.0     45.0     34.0   \n",
       "9              77.0        4.0   1.0      3.0      4.0      9.0     11.0   \n",
       "All          5280.0       72.0  68.0     88.0    137.0    359.0    303.0   \n",
       "\n",
       "       Grade 5  Grade 6  Grade 7    ...     HS diploma      GED  some college  \\\n",
       "RAC1P                               ...                                         \n",
       "1        301.0    760.0    880.0    ...       155828.0  17058.0       28869.0   \n",
       "2         58.0    116.0    118.0    ...        10704.0   2521.0        2696.0   \n",
       "3          1.0     16.0      4.0    ...          144.0     36.0          40.0   \n",
       "4          NaN      1.0      NaN    ...            2.0      1.0           2.0   \n",
       "5          NaN      3.0      5.0    ...           69.0     17.0          19.0   \n",
       "6         65.0    116.0     53.0    ...         1847.0    163.0         583.0   \n",
       "7          NaN      NaN      NaN    ...           35.0     10.0          10.0   \n",
       "8         53.0    129.0     60.0    ...         1397.0    329.0         329.0   \n",
       "9         13.0     34.0     21.0    ...         1415.0    337.0         531.0   \n",
       "All      491.0   1175.0   1141.0    ...       171441.0  20472.0       33079.0   \n",
       "\n",
       "       1+ year college  Associate  Bachelor   Master  Professional  Doctorate  \\\n",
       "RAC1P                                                                           \n",
       "1              52859.0    37029.0   76093.0  33779.0        7413.0     5328.0   \n",
       "2               6011.0     2318.0    3326.0   1607.0         271.0      234.0   \n",
       "3                 75.0       33.0      68.0     37.0           4.0        6.0   \n",
       "4                  NaN        NaN       2.0      1.0           NaN        1.0   \n",
       "5                 36.0       19.0      22.0      3.0           5.0        1.0   \n",
       "6               1363.0      515.0    2982.0   1834.0         666.0      695.0   \n",
       "7                 15.0        6.0      16.0     12.0           1.0        2.0   \n",
       "8                588.0      267.0     356.0    117.0          33.0       25.0   \n",
       "9               1135.0      456.0     877.0    348.0         107.0       67.0   \n",
       "All            62082.0    40643.0   83742.0  37738.0        8500.0     6359.0   \n",
       "\n",
       "            ALL  \n",
       "RAC1P            \n",
       "1      456843.0  \n",
       "2       35469.0  \n",
       "3         543.0  \n",
       "4          10.0  \n",
       "5         268.0  \n",
       "6       12446.0  \n",
       "7         122.0  \n",
       "8        5044.0  \n",
       "9        6079.0  \n",
       "All    516824.0  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a table showing total count of educational attaninment of adults in PA by race. \n",
    "pivot_pa = pd.pivot_table(new_pa,\n",
    "                              index='RAC1P',\n",
    "                              columns='SCHL',\n",
    "                              values='PINCP',\n",
    "                              aggfunc=np.size,\n",
    "                              margins=True)\n",
    "\n",
    "pivot_pa.columns = ['No schooling','preschool','K','Grade 1','Grade 2','Grade 3','Grade 4','Grade 5','Grade 6','Grade 7','Grade 8'\n",
    "                        ,'Grade 9','Grade 10','Grade 11','Grade 12-no diploma','HS diploma','GED','some college','1+ year college','Associate',\n",
    "                        'Bachelor','Master','Professional','Doctorate','ALL']\n",
    "#TODO: rename columns for clarity.\n",
    "pivot_pa.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Laplace Mechanism**\n",
    "The Laplace mechanism adds Laplace-distributed noise to a function.\n",
    "\n",
    "Notice that the `laplace_mech()` consumes a parameter `epsilon`. We refer to this quantity as the privacy loss of the mechanism and is part of the most central definition in the field of differential privacy: ε-differential privacy. By tuning epsilon, we control the noisiness of our noisy counting. Choosing a smaller epsilon produces noisier results and better privacy guarantees. \n",
    "\n",
    "Generally, the global `sensitivity` of a function is the largest possible difference that one row can have on the result of that function, for any dataset. The larger the `sensitivity`, the noisier the answer will be. Calculating the `sensitivity` for an arbitrary function can be difficult, but we know that any counting query has a `sensitivity` of 1, because adding or removing a single row from any dataset will change the count by at most 1.\n",
    "\n",
    "If S is the `sensitivity` of a function f, a measure of how revealing the function might be, then adding Laplace noise with scale S/ε preserves ε-differential privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def laplace_mech(mu, epsilon, sensitivity=1.0):\n",
    "    \"\"\"Implementation of the Laplace Mechanism that adds Laplacian-distributed noise to a function.\n",
    "  　\n",
    "    Args:\n",
    "      mu (float or numpy array): the true answer\n",
    "      epsilon(int): the privacy budget\n",
    "      sensitivity (float): the global sensitivity of the query\n",
    "    \"\"\"\n",
    "    eps = epsilon/float(sensitivity)\n",
    "    scale = 1/eps\n",
    "    np_shape = np.shape(mu)\n",
    "    shape = None if np_shape == () else np_shape\n",
    "    z = np.random.laplace(0.0, scale=scale, size=shape)\n",
    "    return mu + z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the trade-off between statistical accuracy and privacy loss is at the heart of differential privacy, there are many metrics for assessing the quality of a published dataset. One approach is to calculate the L1 error between the true data (i.e. without disclosure limitation) and the privatized data.\n",
    "\n",
    "**The L1 Norm** In this simple scenario involving the Laplace Mechanism, the L1 error is a natural metric. The L1 norm is basically minimizing the sum of the absolute differences between the target value and the estimated values. This is a coarse measure: a disclosure limited product with a high L1 compared to the same product without disclosure limitation may still be very accurate for its intended use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_l1_laplace(epsilon, mu, n=1000):\n",
    "    \"\"\"Takes the average error of the laplace mechanism on an array over n samples.\n",
    "  　\n",
    "    Args:\n",
    "      epsilon (int): the privacy budget\n",
    "      mu (float or numpy array): the true answer\n",
    "      n (int): number of samples\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        noisy_arr = laplace_mech(mu, epsilon, sensitivity=1.0)\n",
    "        accuracy = 1 - (np.linalg.norm(noisy_arr-mu, 1)/(2*noisy_arr.shape[1]))\n",
    "        total += accuracy\n",
    "    return total/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade-off Between Privacy Loss and Accuracy\n",
    "\n",
    "When submitting to the DRB, the practitioner prepares a set of graphs that show the trade-off between privacy loss (ϵ) and accuracy. The Data Stewardship and Executive Policy committee (DSEP) then picks a value of ϵ that allows for sufficient accuracy. DSEP most often chooses epsilon values between 1 and 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGuri5R3vngQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2065b97ac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_arr = pd.DataFrame(pivot_pa.fillna(0))\n",
    "accuracy_df = pd.DataFrame()\n",
    "eps_range = np.arange(1,6.0,.1)\n",
    "accuracy_df['Privacy Loss (ϵ)'] = eps_range\n",
    "accuracy_df['Accuracy'] = [avg_l1_laplace(x, orig_arr) for x in eps_range]\n",
    "accuracy_df.plot.scatter('Privacy Loss (ϵ)', 'Accuracy')\n",
    "plt.title('Trade-Off Between Privacy Loss and Accuracy')\n",
    "plt.style.use('seaborn-paper')\n",
    "plt.savefig('out/fig.png',facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', ransparent=False, bbox_inches=None, pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing\n",
    "\n",
    "Postprocessing the output of a DP mechanism does not degrade privacy. In this case, we want to round any negative counts to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rounder(x):\n",
    "    '''\n",
    "    Rounding helper function\n",
    "    '''\n",
    "    if x < 0:\n",
    "        return 0 \n",
    "    else:\n",
    "        return round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply rounder to every cell in new noisy output\n",
    "noisy_counts = laplace_mech(orig_arr, 3)\n",
    "rounded_counts = noisy_counts.applymap(rounder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       No schooling  preschool          K    Grade 1     Grade 2     Grade 3  \\\n",
       " RAC1P                                                                          \n",
       " 1       3748.907943  54.008950  48.232236  53.066779   73.352371  230.008151   \n",
       " 2        632.435362  10.010654  12.448741   8.887868   20.454710   38.674936   \n",
       " 3         10.482567   0.836671   0.919400  -0.199677    0.937612    2.192477   \n",
       " 4          0.036330  -0.267501  -0.000071   0.075971    0.178791    0.265819   \n",
       " 5         10.009972   0.144960  -1.093385   1.810930    4.014598    1.173021   \n",
       " 6        570.857701   1.638139   3.330490   7.444449   21.104004   31.188156   \n",
       " 7          3.957572  -0.701023   0.037821  -0.275788   -0.063110    0.678021   \n",
       " 8        225.245910   2.332382   1.822285  12.562392   13.170322   44.623966   \n",
       " 9         76.939556   5.086405   1.516858   2.928448    3.999311    8.973780   \n",
       " All     5280.727580  72.341106  68.111183  87.991068  137.729232  359.086602   \n",
       " \n",
       "           Grade 4     Grade 5      Grade 6      Grade 7      ...        \\\n",
       " RAC1P                                                        ...         \n",
       " 1      191.803990  301.044317   759.590387   879.300748      ...         \n",
       " 2       27.034083   58.128523   115.843309   118.047000      ...         \n",
       " 3        0.323340    0.604144    16.055499     2.408752      ...         \n",
       " 4        0.220876   -0.293257     1.257521    -0.227447      ...         \n",
       " 5        3.205346    0.184940     3.078940     4.966740      ...         \n",
       " 6       34.952806   65.357677   117.591976    51.971954      ...         \n",
       " 7        0.152686    0.252274     0.219530    -0.275192      ...         \n",
       " 8       34.984163   53.002455   128.984439    59.928241      ...         \n",
       " 9       11.701685   12.044449    34.054379    20.629687      ...         \n",
       " All    303.487770  491.267399  1174.988499  1141.034057      ...         \n",
       " \n",
       "           HS diploma           GED  some college  1+ year college  \\\n",
       " RAC1P                                                               \n",
       " 1      155828.041613  17057.611847  28868.405732     52858.887378   \n",
       " 2       10704.334479   2520.889937   2696.175043      6011.230431   \n",
       " 3         144.479300     35.842333     39.744303        75.206684   \n",
       " 4           2.852555      1.271610      2.390674        -0.371305   \n",
       " 5          69.104554     16.920397     19.001972        35.699771   \n",
       " 6        1847.011155    162.618131    583.227889      1363.447880   \n",
       " 7          34.988496     10.526722     11.146243        15.061373   \n",
       " 8        1397.547133    328.741944    329.371798       587.809749   \n",
       " 9        1416.070041    336.595620    531.048332      1135.100753   \n",
       " All    171440.924582  20471.696130  33078.672961     62081.781362   \n",
       " \n",
       "           Associate      Bachelor        Master  Professional    Doctorate  \\\n",
       " RAC1P                                                                        \n",
       " 1      37028.658991  76092.847874  33778.640902   7412.928011  5328.597085   \n",
       " 2       2317.301435   3325.899272   1607.154442    270.581139   233.903210   \n",
       " 3         33.701612     68.117878     37.110633      2.318660     5.775824   \n",
       " 4         -0.106080      1.896068      2.626967     -0.268264     1.227852   \n",
       " 5         17.045366     22.088678      2.568836      5.430493     1.253138   \n",
       " 6        514.946505   2980.930501   1833.449569    665.860078   694.823922   \n",
       " 7          6.025864     15.575953     12.090338      1.181303     1.873659   \n",
       " 8        267.395799    356.612535    117.043173     32.546484    24.333271   \n",
       " 9        455.259573    878.681759    348.302244    107.452303    67.116051   \n",
       " All    40643.052209  83741.843381  37737.927835   8500.063664  6358.804421   \n",
       " \n",
       "                  ALL  \n",
       " RAC1P                 \n",
       " 1      456842.720145  \n",
       " 2       35469.181885  \n",
       " 3         542.940912  \n",
       " 4           9.429013  \n",
       " 5         268.630327  \n",
       " 6       12446.862802  \n",
       " 7         121.602840  \n",
       " 8        5043.745867  \n",
       " 9        6079.118148  \n",
       " All    516824.309734  \n",
       " \n",
       " [10 rows x 25 columns],\n",
       "        No schooling  preschool   K  Grade 1  Grade 2  Grade 3  Grade 4  \\\n",
       " RAC1P                                                                    \n",
       " 1              3749         54  48       53       73      230      192   \n",
       " 2               632         10  12        9       20       39       27   \n",
       " 3                10          1   1        0        1        2        0   \n",
       " 4                 0          0   0        0        0        0        0   \n",
       " 5                10          0   0        2        4        1        3   \n",
       " 6               571          2   3        7       21       31       35   \n",
       " 7                 4          0   0        0        0        1        0   \n",
       " 8               225          2   2       13       13       45       35   \n",
       " 9                77          5   2        3        4        9       12   \n",
       " All            5281         72  68       88      138      359      303   \n",
       " \n",
       "        Grade 5  Grade 6  Grade 7   ...    HS diploma    GED  some college  \\\n",
       " RAC1P                              ...                                      \n",
       " 1          301      760      879   ...        155828  17058         28868   \n",
       " 2           58      116      118   ...         10704   2521          2696   \n",
       " 3            1       16        2   ...           144     36            40   \n",
       " 4            0        1        0   ...             3      1             2   \n",
       " 5            0        3        5   ...            69     17            19   \n",
       " 6           65      118       52   ...          1847    163           583   \n",
       " 7            0        0        0   ...            35     11            11   \n",
       " 8           53      129       60   ...          1398    329           329   \n",
       " 9           12       34       21   ...          1416    337           531   \n",
       " All        491     1175     1141   ...        171441  20472         33079   \n",
       " \n",
       "        1+ year college  Associate  Bachelor  Master  Professional  Doctorate  \\\n",
       " RAC1P                                                                          \n",
       " 1                52859      37029     76093   33779          7413       5329   \n",
       " 2                 6011       2317      3326    1607           271        234   \n",
       " 3                   75         34        68      37             2          6   \n",
       " 4                    0          0         2       3             0          1   \n",
       " 5                   36         17        22       3             5          1   \n",
       " 6                 1363        515      2981    1833           666        695   \n",
       " 7                   15          6        16      12             1          2   \n",
       " 8                  588        267       357     117            33         24   \n",
       " 9                 1135        455       879     348           107         67   \n",
       " All              62082      40643     83742   37738          8500       6359   \n",
       " \n",
       "           ALL  \n",
       " RAC1P          \n",
       " 1      456843  \n",
       " 2       35469  \n",
       " 3         543  \n",
       " 4           9  \n",
       " 5         269  \n",
       " 6       12447  \n",
       " 7         122  \n",
       " 8        5044  \n",
       " 9        6079  \n",
       " All    516824  \n",
       " \n",
       " [10 rows x 25 columns])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_counts, rounded_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
