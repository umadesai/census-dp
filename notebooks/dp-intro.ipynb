{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem:   Given a dataset with sensitive personal information, how can one compute and release functions of the dataset while protecting individual privacy?\n",
    "\n",
    "### SDL techniques are no longer sufficient.\n",
    "Recent privacy failures have showed us that redaction of identifiers is insufficient for protecting privacy, and auxiliary information needs to be taken into account. We need to recognize that *any* useful analysis of personal data *must* leak some information about individuals, and these leakages *accumulate* with multiple analyses.\n",
    "\n",
    "### Differential Privacy\n",
    "- mathematically provable privacy guarantee\n",
    "- states that any information-related risk to a person should not change signicantly as a result of that person's information being indcluded, or not, in the analysis\n",
    "\n",
    "### [A Privacy \"Budget\"](https://github.com/umadesai/census-dp/blob/master/notebooks/dp-budget.ipynb)\n",
    "- DP provides provable privacy guarantees with respect to the cumulative risk from successive data releases\n",
    "- Setting the budget is a policy question\n",
    "\n",
    "### Differentitially Private Computations\n",
    "Algorithms maintain differential privacy via the introduction of carefully crafted random noise into the computation. \n",
    "\n",
    "Types of computations that can be made differentiallly private:\n",
    "- descriptive statistics\n",
    "    - [counts](https://github.com/umadesai/census-dp/blob/master/notebooks/dp-count.ipynb)\n",
    "    - [mean](https://github.com/umadesai/census-dp/blob/master/notebooks/dp-mean.ipynb)\n",
    "    - [median](https://github.com/umadesai/census-dp/blob/master/notebooks/dp-median.ipynb)\n",
    "    - histograms\n",
    "    - boxplots\n",
    "    - [cdf](https://github.com/umadesai/census-dp/blob/master/notebooks/dp-mm.ipynb)\n",
    "- supervised and unsupervised ML tasks\n",
    "    - [regression](https://github.com/umadesai/census-dp/blob/master/notebooks/dp-regression.ipynb)\n",
    "    - classification\n",
    "- generation of synthetic data\n",
    "\n",
    "### Read more\n",
    "- [Differential Privacy: An Introduction For Statistical Agencies](https://gss.civilservice.gov.uk/wp-content/uploads/2018/12/12-12-18_FINAL_Privitar_Kobbi_Nissim_article.pdf) Page et al.\n",
    "- [Differential Privacy: A Primer for a Non-technical Audience](http://www.jetlaw.org/wp-content/uploads/2018/12/4_Wood_Final.pdf) Wood et al.\n",
    "- [A Firm Foundation for Private Data Analysis](http://delivery.acm.org/10.1145/1870000/1866758/p86-dwork.pdf?ip=108.28.104.96&id=1866758&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1562937387_c049c03e734df8e04aac19ab857b3961) Dwork.\n",
    "- [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf) Dwork & Roth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
